{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhR_uffZA00V"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import gdown\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5333,
     "status": "ok",
     "timestamp": 1752983401836,
     "user": {
      "displayName": "MDR Sandamini",
      "userId": "14130589177191734805"
     },
     "user_tz": -330
    },
    "id": "6AVtX9vLA5Vs",
    "outputId": "29c7265c-114b-4691-ec23-1c1db44303ab"
   },
   "outputs": [],
   "source": [
    "file_id = \"file_id\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"texture_uni.zip\", quiet=False)\n",
    "with zipfile.ZipFile(\"texture_uni.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"texture_uni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lV6gCotSA6U"
   },
   "source": [
    "## Creating Combinations - University Dataset\n",
    "#### Output - train.csv, test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1752983403586,
     "user": {
      "displayName": "MDR Sandamini",
      "userId": "14130589177191734805"
     },
     "user_tz": -330
    },
    "id": "D5Rm-SFtWviA",
    "outputId": "bfa86dc0-0668-4ea4-b9e0-2dfde3232f0d"
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"texture_uni\"\n",
    "random.seed(42)\n",
    "\n",
    "writer_data = {}\n",
    "\n",
    "for writer_id in os.listdir(BASE_PATH):\n",
    "    writer_path = os.path.join(BASE_PATH, writer_id) # texture/W001\n",
    "    if not os.path.isdir(writer_path):\n",
    "        continue\n",
    "    writer_data[writer_id] = {}\n",
    "    for sample in os.listdir(writer_path):\n",
    "        sample_path = os.path.join(writer_path, sample) # texture/W001/S01_F\n",
    "        if not os.path.isdir(sample_path):\n",
    "            continue\n",
    "        writer_data[writer_id][sample] = []\n",
    "        for img in os.listdir(sample_path):\n",
    "            if img.endswith(\".png\"):\n",
    "                img = img.replace(\".png\",\"\")\n",
    "                rel_path = os.path.join(BASE_PATH, writer_id, sample, img) # texture/W001/S01_F/W001_S01_F_T1\n",
    "                writer_data[writer_id][sample].append(rel_path)\n",
    "\n",
    "all_writers = list(writer_data.keys())\n",
    "\n",
    "train_writers, val_test_writers = train_test_split(\n",
    "    all_writers,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_writers, test_writers = train_test_split(\n",
    "    val_test_writers,\n",
    "    test_size=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "def generate_pairs(writers, mode=\"train\"):\n",
    "    genuine_pairs = []\n",
    "    impostor_pairs = []\n",
    "\n",
    "    for writer in writers:\n",
    "        samples = list(writer_data[writer].keys())\n",
    "        if len(samples) < 2:\n",
    "            continue\n",
    "\n",
    "        for sample in samples:\n",
    "            textures = writer_data[writer][sample]\n",
    "            for i in range(len(textures)):\n",
    "                for j in range(i + 1, len(textures)):\n",
    "                    genuine_pairs.append((textures[i], textures[j], 0))\n",
    "\n",
    "        for i in range(len(samples)):\n",
    "            for j in range(i + 1, len(samples)):\n",
    "                imgs1 = writer_data[writer][samples[i]]\n",
    "                imgs2 = writer_data[writer][samples[j]]\n",
    "                for img1 in imgs1:\n",
    "                    for img2 in imgs2:\n",
    "                        genuine_pairs.append((img1, img2, 0))\n",
    "\n",
    "    impostor_set = set()\n",
    "\n",
    "    while len(impostor_set) < len(genuine_pairs):\n",
    "        w1, w2 = random.sample(writers, 2)\n",
    "        sample1 = random.choice(list(writer_data[w1].keys()))\n",
    "        sample2 = random.choice(list(writer_data[w2].keys()))\n",
    "        img1 = random.choice(writer_data[w1][sample1])\n",
    "        img2 = random.choice(writer_data[w2][sample2])\n",
    "\n",
    "        pair = tuple(sorted([img1, img2]))\n",
    "        if pair not in impostor_set:\n",
    "            impostor_set.add(pair)\n",
    "            impostor_pairs.append((img1, img2, 1))\n",
    "\n",
    "    print(f\"{mode.title()} Set — Genuine: {len(genuine_pairs)}, Impostor: {len(impostor_pairs)}\")\n",
    "    all_pairs = genuine_pairs + impostor_pairs\n",
    "    random.shuffle(all_pairs)\n",
    "\n",
    "    df = pd.DataFrame(all_pairs, columns=[\"sample_1\", \"sample_2\", \"label\"])\n",
    "    df.to_csv(f\"uni_{mode}.csv\", index=False)\n",
    "    df.to_parquet(\n",
    "        f\"uni_{mode}.parquet\",\n",
    "        index=False,\n",
    "        compression=\"snappy\"\n",
    "    )\n",
    "\n",
    "generate_pairs(train_writers, mode=\"train\")\n",
    "generate_pairs(val_writers, mode=\"val\")\n",
    "generate_pairs(test_writers, mode=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DhtK5BZlR9r"
   },
   "source": [
    "## Creating Combinations - CVL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6750,
     "status": "ok",
     "timestamp": 1746205555680,
     "user": {
      "displayName": "Rashmi Sandamini",
      "userId": "17082450369188033534"
     },
     "user_tz": -330
    },
    "id": "ZnjDtneelRvA",
    "outputId": "cd6709fc-fff6-4ba3-ba9c-40953d60a556"
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "CVL_PATH = \"texture_cvl\"\n",
    "same_writer_pairs = []\n",
    "diff_writer_pairs = []\n",
    "\n",
    "writer_data = defaultdict(lambda: defaultdict(list))  # writer_id -> sample_number -> [file paths]\n",
    "\n",
    "for writer_id in os.listdir(CVL_PATH):\n",
    "    writer_path = os.path.join(CVL_PATH, writer_id) # texture_cvl/CVL0001\n",
    "    if not os.path.isdir(writer_path):\n",
    "        continue\n",
    "\n",
    "    for sample_folder in os.listdir(writer_path):\n",
    "        sample_path = os.path.join(writer_path, sample_folder) # texture_cvl/CVL0001/CVL0001_1\n",
    "        if not os.path.isdir(sample_path):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(sample_path): # eg: CVL0001_1_T1.png\n",
    "          if file.endswith(\".png\"):\n",
    "              parts = file.split(\"_\") # CVL0001/1/T1.png\n",
    "              sample_num = parts[1] # 1\n",
    "              file_path_no_ext = os.path.join(sample_path, file).replace(\".png\", \"\") # texture_cvl/CVL0001/CVL0001_1/CVL0001_1_T1\n",
    "              writer_data[writer_id][sample_num].append(file_path_no_ext)\n",
    "\n",
    "all_writers = list(writer_data.keys())\n",
    "train_writers, val_test_writers = train_test_split(\n",
    "    all_writers,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42)\n",
    "\n",
    "val_writers, test_writers = train_test_split(\n",
    "    val_test_writers,\n",
    "    test_size = 0.5,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "def generate_pairs(writers, mode=\"train\"):\n",
    "    genuine_pairs = []\n",
    "    impostor_pairs = []\n",
    "\n",
    "    for writer in writers:\n",
    "        samples = list(writer_data[writer].keys())\n",
    "\n",
    "        for sample_num in samples:\n",
    "            textures = writer_data[writer][sample_num]\n",
    "            for i in range(len(textures)):\n",
    "                for j in range(i + 1, len(textures)):\n",
    "                    genuine_pairs.append((textures[i], textures[j], 0))\n",
    "\n",
    "        for s1, s2 in combinations(samples, 2):\n",
    "            for f1 in writer_data[writer][s1]:\n",
    "                for f2 in writer_data[writer][s2]:\n",
    "                    genuine_pairs.append((f1, f2, 0))\n",
    "\n",
    "    impostor_set = set()\n",
    "    while len(impostor_set) < len(genuine_pairs):\n",
    "        w1, w2 = random.sample(writers, 2)\n",
    "        sample1 = random.choice(list(writer_data[w1].keys()))\n",
    "        sample2 = random.choice(list(writer_data[w2].keys()))\n",
    "        img1 = random.choice(writer_data[w1][sample1])\n",
    "        img2 = random.choice(writer_data[w2][sample2])\n",
    "        pair = tuple(sorted([img1, img2]))\n",
    "        if pair not in impostor_set:\n",
    "            impostor_set.add(pair)\n",
    "            impostor_pairs.append((img1, img2, 1))  # Label 1 for different writers\n",
    "\n",
    "    all_pairs = genuine_pairs + impostor_pairs\n",
    "    random.shuffle(all_pairs)\n",
    "\n",
    "    df = pd.DataFrame(all_pairs, columns=[\"sample_1\", \"sample_2\", \"label\"])\n",
    "    df.to_csv(f\"cvl_{mode}.csv\", index=False)\n",
    "    df.to_parquet(\n",
    "        f\"cvl_{mode}.parquet\",\n",
    "        index=False,\n",
    "        compression=\"snappy\"\n",
    "    )\n",
    "    print(f\"{mode.title()} Set — Genuine: {len(genuine_pairs)}, Impostor: {len(impostor_pairs)}\")\n",
    "\n",
    "generate_pairs(train_writers, mode=\"train\")\n",
    "generate_pairs(val_writers, mode=\"val\")\n",
    "generate_pairs(test_writers, mode=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38596,
     "status": "ok",
     "timestamp": 1746205754114,
     "user": {
      "displayName": "Rashmi Sandamini",
      "userId": "17082450369188033534"
     },
     "user_tz": -330
    },
    "id": "HTMJSx4Xs_fP",
    "outputId": "82eff93c-83f4-4283-e31d-cf6ccc4a2a2c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, ['cvl_train.csv', 'uni_train.csv']), ignore_index=True)\n",
    "df.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, ['cvl_val.csv', 'uni_val.csv']), ignore_index=True)\n",
    "df.to_csv(\"val.csv\", index=False)\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, ['cvl_test.csv', 'uni_test.csv']), ignore_index=True)\n",
    "df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "target_directory = \"/content/drive/MyDrive/Research Level 4/Implementations/Writer Verification Rashmi/data/version_3/0.15 split/csv files\"\n",
    "!cp uni_train.csv \"{target_directory}/\"\n",
    "!cp cvl_train.csv \"{target_directory}/\"\n",
    "!cp uni_test.csv \"{target_directory}/\"\n",
    "!cp cvl_test.csv \"{target_directory}/\"\n",
    "!cp uni_val.csv \"{target_directory}/\"\n",
    "!cp cvl_val.csv \"{target_directory}/\"\n",
    "!cp test.csv \"{target_directory}/\"\n",
    "!cp train.csv \"{target_directory}/\"\n",
    "!cp val.csv \"{target_directory}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QedTilp1vDhD"
   },
   "outputs": [],
   "source": [
    "df = pd.concat(map(pd.read_parquet, ['cvl_train.parquet', 'uni_train.parquet']), ignore_index=True)\n",
    "df.to_parquet(\"train.parquet\", index=False, compression=\"snappy\")\n",
    "\n",
    "df = pd.concat(map(pd.read_parquet, ['cvl_val.parquet', 'uni_val.parquet']), ignore_index=True)\n",
    "df.to_parquet(\"val.parquet\", index=False, compression=\"snappy\")\n",
    "\n",
    "df = pd.concat(map(pd.read_parquet, ['cvl_test.parquet', 'uni_test.parquet']), ignore_index=True)\n",
    "df.to_parquet(\"test.parquet\", index=False, compression=\"snappy\")\n",
    "\n",
    "target_directory = \"/content/drive/MyDrive/Research Level 4/Implementations/Writer Verification Rashmi/data/version_3/0.15 split/parquet files\"\n",
    "!cp uni_train.parquet \"{target_directory}/\"\n",
    "!cp cvl_train.parquet \"{target_directory}/\"\n",
    "!cp uni_test.parquet \"{target_directory}/\"\n",
    "!cp cvl_test.parquet \"{target_directory}/\"\n",
    "!cp uni_val.parquet \"{target_directory}/\"\n",
    "!cp cvl_val.parquet \"{target_directory}/\"\n",
    "!cp test.parquet \"{target_directory}/\"\n",
    "!cp train.parquet \"{target_directory}/\"\n",
    "!cp val.parquet \"{target_directory}/\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6lV6gCotSA6U",
    "-DhtK5BZlR9r"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
