{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxFo6-vB-6i5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import gdown\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85Fk-A7iAK7_"
   },
   "source": [
    "# Creating Textures - University Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7599,
     "status": "ok",
     "timestamp": 1746186157281,
     "user": {
      "displayName": "Rashmi Sandamini",
      "userId": "17082450369188033534"
     },
     "user_tz": -330
    },
    "id": "r9M0m5XH9Zug",
    "outputId": "9bb0944d-f431-462a-faff-a0767a1f55ff"
   },
   "outputs": [],
   "source": [
    "file_id = \"file_id\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"binary.zip\", quiet=False)\n",
    "\n",
    "with zipfile.ZipFile(\"binary.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejnZihq7CmxY"
   },
   "source": [
    "## Extracting Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkJOJd-2_ngA"
   },
   "outputs": [],
   "source": [
    "def segment_lines(image, threshold=350000, line_height=180, size=1600):\n",
    "    projection = np.sum(image, axis=1) #horizontal projection\n",
    "    line_start = None\n",
    "    lines = []\n",
    "\n",
    "    for i, value in enumerate(projection):\n",
    "        if value < threshold and line_start is None:\n",
    "            line_start = i\n",
    "        elif value >= threshold and line_start is not None:\n",
    "            lines.append((line_start, i))\n",
    "            line_start = None\n",
    "\n",
    "    cropped_lines = []\n",
    "    for (start, end) in lines:\n",
    "        if end - start < 20:\n",
    "            continue\n",
    "        center = (start + end) // 2\n",
    "        bottom = max(0, center - line_height // 2)\n",
    "        top = min(image.shape[0], center + line_height // 2)\n",
    "        cropped_lines.append(cv2.resize(image[bottom:top, :], (size, line_height)))\n",
    "    return clean_lines(cropped_lines)\n",
    "\n",
    "def clean_lines(dirty_lines):\n",
    "    cleaned_lines = []\n",
    "    for line in dirty_lines:\n",
    "        contours, _ = cv2.findContours(\n",
    "            cv2.bitwise_not(line), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        mask = np.zeros_like(line)\n",
    "        min_area = 40\n",
    "        for contour in contours:\n",
    "            middle_point = False\n",
    "            for point in contour:\n",
    "                if point[0][1] > 40 and point[0][1] < 140:\n",
    "                    middle_point = True\n",
    "                    break\n",
    "            if cv2.contourArea(contour) > min_area and middle_point:\n",
    "                cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "        cleaned_binary = cv2.bitwise_not(cv2.bitwise_and(cv2.bitwise_not(line), mask))\n",
    "        cleaned_lines.append(cleaned_binary)\n",
    "    return cleaned_lines, dirty_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGRD6krsDAUg"
   },
   "source": [
    "## Extracting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Md0SyWU_xEE"
   },
   "outputs": [],
   "source": [
    "def segment_words(lines):\n",
    "    cropped_words = []\n",
    "    for line in lines:\n",
    "        vertical_projection = np.sum(line, axis=0)\n",
    "        word_threshold = 45000\n",
    "        word_start = None\n",
    "        words = []\n",
    "        consecutive_count = 0\n",
    "        min_consecutive = 15\n",
    "        for i, value in enumerate(vertical_projection):\n",
    "            if value < word_threshold:\n",
    "                consecutive_count = 0\n",
    "                if word_start is None:\n",
    "                    word_start = i\n",
    "            elif value >= word_threshold:\n",
    "                if word_start is not None:\n",
    "                    consecutive_count += 1\n",
    "                    if consecutive_count >= min_consecutive:\n",
    "                        words.append((word_start, i - min_consecutive + 1))\n",
    "                        word_start = None\n",
    "                        consecutive_count = 0\n",
    "        for word in words:\n",
    "            start, end = word\n",
    "            cropped_words.append(line[:, start:end])\n",
    "    return cropped_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdPEccosdlhF"
   },
   "source": [
    "## Generating Texture - Line Filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Hs54lNPYbSdk"
   },
   "outputs": [],
   "source": [
    "def generate_texture(cropped_words, file_name=\"unknown\"):\n",
    "    canvas_height = 1400\n",
    "    canvas_width = 1400\n",
    "    if not cropped_words:\n",
    "        print(f\"[WARNING] No cropped words for file: {file_name}\")\n",
    "        return np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "\n",
    "    row_spacing = -100\n",
    "    column_spacing = 0\n",
    "\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    current_width = 0\n",
    "\n",
    "    for word in cropped_words:\n",
    "        word_height, word_width = word.shape\n",
    "\n",
    "        while word_width > 0:\n",
    "            remaining_space = canvas_width - current_width\n",
    "\n",
    "            if remaining_space >= word_width:\n",
    "                current_row.append(word)\n",
    "                current_width += word_width + column_spacing\n",
    "                break\n",
    "            else:\n",
    "                if remaining_space > 0:\n",
    "                    word_part = word[:, :remaining_space]\n",
    "                    current_row.append(word_part)\n",
    "                    word = word[:, remaining_space:]\n",
    "                    word_width = word.shape[1]\n",
    "                rows.append(current_row)\n",
    "                current_row = []\n",
    "                current_width = 0\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[WARNING] No rows could be constructed from the cropped words in file: {file_name}\")\n",
    "        return np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "\n",
    "    used_width = sum(w.shape[1] for w in rows[-1]) + column_spacing * (len(rows[-1]) - 1)\n",
    "    remaining_space = canvas_width - used_width\n",
    "    for w in rows[0]:\n",
    "      if remaining_space <= 0:\n",
    "          break\n",
    "      h, w_w = w.shape\n",
    "      if w_w + column_spacing <= remaining_space:\n",
    "          rows[-1].append(w)\n",
    "          remaining_space -= (w_w + column_spacing)\n",
    "      else:\n",
    "          slice_width = remaining_space\n",
    "          rows[-1].append(w[:, :slice_width])\n",
    "          remaining_space = 0\n",
    "\n",
    "\n",
    "    texture = np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "\n",
    "    y_offset = 0\n",
    "    row_index = 0\n",
    "\n",
    "    while y_offset < canvas_height:\n",
    "        row = rows[row_index % len(rows)]\n",
    "        x_offset = 0\n",
    "        max_row_height = max(word.shape[0] for word in row)\n",
    "\n",
    "        if y_offset + max_row_height > canvas_height:\n",
    "            break\n",
    "\n",
    "        for word in row:\n",
    "            word_height, word_width = word.shape\n",
    "            if y_offset + word_height <= canvas_height and x_offset + word_width <= canvas_width:\n",
    "                word_text = np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "                word_text[y_offset:y_offset + word_height, x_offset:x_offset + word_width] = word\n",
    "                texture = cv2.bitwise_not(cv2.bitwise_or(cv2.bitwise_not(texture), cv2.bitwise_not(word_text)))\n",
    "            x_offset += word_width + column_spacing\n",
    "\n",
    "        y_offset += max_row_height + row_spacing\n",
    "        row_index += 1\n",
    "\n",
    "    crop_size = 1350\n",
    "\n",
    "    h, w = texture.shape\n",
    "    y_start = (h - crop_size) // 2\n",
    "    x_start = (w - crop_size) // 2\n",
    "    y_end   = y_start + crop_size\n",
    "    x_end   = x_start + crop_size\n",
    "\n",
    "    texture = texture[\n",
    "        y_start : y_end,\n",
    "        x_start : x_end\n",
    "    ]\n",
    "\n",
    "    return texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvovg8VZeGLq"
   },
   "outputs": [],
   "source": [
    "def split_texture(texture):\n",
    "\n",
    "    patch_size = 450\n",
    "    patches = []\n",
    "\n",
    "    for i in range(3):  \n",
    "        for j in range(3):  \n",
    "            y_start = i * patch_size\n",
    "            x_start = j * patch_size\n",
    "            patch = texture[y_start:y_start + patch_size, x_start:x_start + patch_size]\n",
    "            patches.append(patch)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHBPi56-lEB-"
   },
   "source": [
    "## Create Textures for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295039,
     "status": "ok",
     "timestamp": 1746186455464,
     "user": {
      "displayName": "Rashmi Sandamini",
      "userId": "17082450369188033534"
     },
     "user_tz": -330
    },
    "id": "ECGsMJk-lDma",
    "outputId": "a448ebbf-553c-4517-a459-4581a4a6d5fa"
   },
   "outputs": [],
   "source": [
    "input_root = 'dataset/binary'\n",
    "output_root = 'texture'\n",
    "\n",
    "for writer_id in tqdm(sorted(os.listdir(input_root))):\n",
    "    writer_path = os.path.join(input_root, writer_id) #dataset/binary/W001\n",
    "    if not os.path.isdir(writer_path):\n",
    "        continue\n",
    "\n",
    "    for filename in sorted(os.listdir(writer_path)):\n",
    "        if not filename.endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(writer_path, filename) #dataset/binary/W001/W001_S01_F.png\n",
    "        try:\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            cleaned_lines, _ = segment_lines(image)\n",
    "\n",
    "            cropped_words = segment_words(cleaned_lines)\n",
    "\n",
    "            texture = generate_texture(cropped_words, file_name = image_path)\n",
    "\n",
    "            patches = split_texture(texture)\n",
    "\n",
    "            parts = filename.split(\"_\") #W001,S01,F.png\n",
    "            base_id = parts[0] #W001\n",
    "            sample_id = parts[1] #S01\n",
    "            speed = parts[2].split(\".\")[0] #F\n",
    "            subfolder = f\"{sample_id}_{speed}\" #S01_F\n",
    "\n",
    "            save_dir = os.path.join(output_root, base_id, subfolder) #texture/#W001/S01_F\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            for i, patch in enumerate(patches):\n",
    "                patch_filename = f\"{base_id}_{sample_id}_{speed}_T{i+1}.png\" #W001_S01_F_T1.png\n",
    "                patch_path = os.path.join(save_dir, patch_filename) #texture/#W001/S01_F/W001_S01_F_T1.png\n",
    "                cv2.imwrite(patch_path, patch)\n",
    "\n",
    "        except Exception as e:\n",
    "          print(f\"[ERROR] Failed processing: {image_path}\")\n",
    "          print(f\"        {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk-tmS_kuFpo"
   },
   "source": [
    "## Upload Textures to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 47561,
     "status": "ok",
     "timestamp": 1746186882180,
     "user": {
      "displayName": "Rashmi Sandamini",
      "userId": "17082450369188033534"
     },
     "user_tz": -330
    },
    "id": "eu0uhRTBshn4",
    "outputId": "b76e3f42-38eb-4c62-95c2-9dc7d729b0b5"
   },
   "outputs": [],
   "source": [
    "shutil.make_archive(\"texture\", 'zip', \"texture\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"texture.zip\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "target_directory = \"/content/drive/MyDrive/Research Level 4/Implementations/Writer Verification Rashmi/data\"\n",
    "!cp texture.zip \"{target_directory}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "junVADgmbo2H"
   },
   "source": [
    "# Creating Textures - CVL Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_liSm1k9bxOV"
   },
   "source": [
    "## Binarize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aTUdJd6b6N2"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"cvl\"\n",
    "BINARY_OUTPUT_PATH = \"data/binary_cvl\"\n",
    "RAW_OUTPUT_PATH = \"data/raw_cvl\"\n",
    "\n",
    "file_id = \"file_id\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"cvl.zip\", quiet=False)\n",
    "with zipfile.ZipFile(\"cvl.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "writer_folders = sorted(os.listdir(DATASET_PATH))\n",
    "total_images = sum(\n",
    "    len(os.listdir(os.path.join(DATASET_PATH, wf)))\n",
    "    for wf in writer_folders\n",
    "    if os.path.isdir(os.path.join(DATASET_PATH, wf))\n",
    ")\n",
    "\n",
    "def read_image(image_path, resize=True, size=1600):\n",
    "    image = cv2.imread(image_path)\n",
    "    if resize:\n",
    "        image = cv2.resize(image, (size, size))\n",
    "    return image\n",
    "\n",
    "def binarize_only(input):\n",
    "    image = input.copy()\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    raw_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary = cv2.threshold(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_OTSU)\n",
    "    return raw_image, binary\n",
    "\n",
    "def preprocess(writer_path, img_file):\n",
    "    img_path = os.path.join(writer_path, img_file)\n",
    "    image = read_image(img_path)\n",
    "    raw_image, binary_image = binarize_only(image)\n",
    "\n",
    "    writer_folder = os.path.basename(writer_path)\n",
    "    binary_output_folder = os.path.join(BINARY_OUTPUT_PATH, writer_folder)\n",
    "    raw_output_folder = os.path.join(RAW_OUTPUT_PATH, writer_folder)\n",
    "\n",
    "    os.makedirs(binary_output_folder, exist_ok=True)\n",
    "    os.makedirs(raw_output_folder, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(os.path.join(binary_output_folder, img_file), binary_image)\n",
    "    cv2.imwrite(os.path.join(raw_output_folder, img_file), raw_image)\n",
    "\n",
    "with tqdm(\n",
    "    total=total_images, desc=\"Preprocessing\", position=0, leave=True\n",
    ") as progress_bar:\n",
    "    for writer_folder in writer_folders:\n",
    "        writer_path = os.path.join(DATASET_PATH, writer_folder)\n",
    "\n",
    "        if not os.path.isdir(writer_path) or not writer_folder.startswith(\"CVL\"):\n",
    "            print(\"Found folder:\", writer_folder)\n",
    "            continue\n",
    "\n",
    "        images = sorted(os.listdir(writer_path))\n",
    "\n",
    "        for img_file in images:\n",
    "            print(f\"Processinggg {img_file} in {writer_folder}\")\n",
    "            preprocess(writer_path, img_file)\n",
    "            progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BPZIPsvzR5v"
   },
   "outputs": [],
   "source": [
    "!zip -r data.zip data/\n",
    "from google.colab import files\n",
    "files.download('data.zip')\n",
    "\n",
    "!zip -r binary_cvl.zip data/binary_cvl\n",
    "!zip -r raw_cvl.zip data/raw_cvl\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "target_directory = \"/content/drive/MyDrive/Research Level 4/Implementations/Writer Verification Rashmi\"\n",
    "!cp raw_cvl.zip \"{target_directory}/\"\n",
    "\n",
    "target_directory = \"/content/drive/MyDrive/Research Level 4/Implementations/Writer Verification Rashmi\"\n",
    "!cp binary_cvl.zip \"{target_directory}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCjbJ1CqPmwS"
   },
   "source": [
    "## Extracting Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLp_n6X4QBgT"
   },
   "outputs": [],
   "source": [
    "file_id = \"file_id\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"binary_cvl.zip\", quiet=False)\n",
    "\n",
    "with zipfile.ZipFile(\"binary_cvl.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"cvl_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLWURKzlPr6p"
   },
   "outputs": [],
   "source": [
    "def segment_lines(image, threshold=380000, line_height=180, size=1600):\n",
    "    projection = np.sum(image, axis=1)\n",
    "    line_start = None\n",
    "    lines = []\n",
    "\n",
    "    for i, value in enumerate(projection):\n",
    "        if value < threshold and line_start is None:\n",
    "            line_start = i\n",
    "        elif value >= threshold and line_start is not None:\n",
    "            lines.append((line_start, i))\n",
    "            line_start = None\n",
    "\n",
    "    cropped_lines = []\n",
    "    for (start, end) in lines:\n",
    "        if end - start < 20:\n",
    "            continue\n",
    "        center = (start + end) // 2\n",
    "        bottom = max(0, center - line_height // 2)\n",
    "        top = min(image.shape[0], center + line_height // 2)\n",
    "        cropped_lines.append(cv2.resize(image[bottom:top, :], (size, line_height)))\n",
    "    return clean_lines(cropped_lines)\n",
    "\n",
    "def clean_lines(dirty_lines):\n",
    "    cleaned_lines = []\n",
    "    for line in dirty_lines:\n",
    "        contours, _ = cv2.findContours(\n",
    "            cv2.bitwise_not(line), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        mask = np.zeros_like(line)\n",
    "        min_area = 40\n",
    "        for contour in contours:\n",
    "            middle_point = False\n",
    "            for point in contour:\n",
    "                if point[0][1] > 40 and point[0][1] < 140:\n",
    "                    middle_point = True\n",
    "                    break\n",
    "            if cv2.contourArea(contour) > min_area and middle_point:\n",
    "                cv2.drawContours(mask, [contour], -1, 255, -1)\n",
    "        cleaned_binary = cv2.bitwise_not(cv2.bitwise_and(cv2.bitwise_not(line), mask))\n",
    "        cleaned_lines.append(cleaned_binary)\n",
    "    return cleaned_lines, dirty_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mlern8QZPz6o"
   },
   "source": [
    "## Extracting Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bThO160AQPdl"
   },
   "outputs": [],
   "source": [
    "def segment_words(lines):\n",
    "    cropped_words = []\n",
    "    for line in lines:\n",
    "        vertical_projection = np.sum(line, axis=0)\n",
    "        word_threshold = 44000\n",
    "        word_start = None\n",
    "        words = []\n",
    "        consecutive_count = 0\n",
    "        min_consecutive = 20\n",
    "        for i, value in enumerate(vertical_projection):\n",
    "            if value < word_threshold:\n",
    "                consecutive_count = 0\n",
    "                if word_start is None:\n",
    "                    word_start = i\n",
    "            elif value >= word_threshold:\n",
    "                if word_start is not None:\n",
    "                    consecutive_count += 1\n",
    "                    if consecutive_count >= min_consecutive:\n",
    "                        words.append((word_start, i - min_consecutive + 1))\n",
    "                        word_start = None\n",
    "                        consecutive_count = 0\n",
    "        for word in words:\n",
    "            start, end = word\n",
    "            cropped_words.append(line[:, start:end])\n",
    "\n",
    "    return cropped_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfsVP8oVQY0R"
   },
   "source": [
    "## Generating Texture - Line Filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pP_x_Rl0QbHd"
   },
   "outputs": [],
   "source": [
    "def generate_texture(cropped_words, file_name=\"unknown\"):\n",
    "    canvas_height = 1400\n",
    "    canvas_width = 1400\n",
    "    if not cropped_words:\n",
    "        print(f\"[WARNING] No cropped words for file: {file_name}\")\n",
    "        return np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "\n",
    "    row_spacing = -100\n",
    "    column_spacing = 0\n",
    "\n",
    "    rows = []\n",
    "    current_row = []\n",
    "    current_width = 0\n",
    "\n",
    "    for word in cropped_words:\n",
    "        word_height, word_width = word.shape\n",
    "\n",
    "        while word_width > 0:\n",
    "            remaining_space = canvas_width - current_width\n",
    "\n",
    "            if remaining_space >= word_width:\n",
    "                current_row.append(word)\n",
    "                current_width += word_width + column_spacing\n",
    "                break\n",
    "            else:\n",
    "                if remaining_space > 0:\n",
    "                    word_part = word[:, :remaining_space]\n",
    "                    current_row.append(word_part)\n",
    "                    word = word[:, remaining_space:]\n",
    "                    word_width = word.shape[1]\n",
    "                rows.append(current_row)\n",
    "                current_row = []\n",
    "                current_width = 0\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[WARNING] No rows could be constructed from the cropped words in file: {file_name}\")\n",
    "        return np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "\n",
    "    if current_row:\n",
    "        rows.append(current_row)\n",
    "\n",
    "\n",
    "    used_width = sum(w.shape[1] for w in rows[-1]) + column_spacing * (len(rows[-1]) - 1)\n",
    "    remaining_space = canvas_width - used_width\n",
    "    for w in rows[0]:\n",
    "      if remaining_space <= 0:\n",
    "          break\n",
    "      h, w_w = w.shape\n",
    "      if w_w + column_spacing <= remaining_space:\n",
    "          rows[-1].append(w)\n",
    "          remaining_space -= (w_w + column_spacing)\n",
    "      else:\n",
    "          slice_width = remaining_space\n",
    "          rows[-1].append(w[:, :slice_width])\n",
    "          remaining_space = 0\n",
    "\n",
    "\n",
    "    texture = np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "\n",
    "    y_offset = 0\n",
    "    row_index = 0\n",
    "\n",
    "    while y_offset < canvas_height:\n",
    "        row = rows[row_index % len(rows)]\n",
    "        x_offset = 0\n",
    "        max_row_height = max(word.shape[0] for word in row)\n",
    "\n",
    "        if y_offset + max_row_height > canvas_height:\n",
    "            break\n",
    "\n",
    "        for word in row:\n",
    "            word_height, word_width = word.shape\n",
    "            if y_offset + word_height <= canvas_height and x_offset + word_width <= canvas_width:\n",
    "                word_text = np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255\n",
    "                word_text[y_offset:y_offset + word_height, x_offset:x_offset + word_width] = word\n",
    "                texture = cv2.bitwise_not(cv2.bitwise_or(cv2.bitwise_not(texture), cv2.bitwise_not(word_text)))\n",
    "            x_offset += word_width + column_spacing\n",
    "\n",
    "        y_offset += max_row_height + row_spacing\n",
    "        row_index += 1\n",
    "\n",
    "    crop_size = 1350\n",
    "\n",
    "    h, w = texture.shape\n",
    "    y_start = (h - crop_size) // 2\n",
    "    x_start = (w - crop_size) // 2\n",
    "    y_end   = y_start + crop_size\n",
    "    x_end   = x_start + crop_size\n",
    "\n",
    "    texture = texture[\n",
    "        y_start : y_end,\n",
    "        x_start : x_end\n",
    "    ]\n",
    "\n",
    "    return texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3p7nLSRQqVJ"
   },
   "outputs": [],
   "source": [
    "def split_texture(texture):\n",
    "\n",
    "    patch_size = 450\n",
    "    patches = []\n",
    "\n",
    "    for i in range(2): \n",
    "        for j in range(2):  \n",
    "            y_start = i * patch_size\n",
    "            x_start = j * patch_size\n",
    "            patch = texture[y_start:y_start + patch_size, x_start:x_start + patch_size]\n",
    "            patches.append(patch)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jiSvzbAQxd7"
   },
   "source": [
    "## Creating Textures for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj2SA4Q7RLir"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_root = 'cvl_dataset/data/binary_cvl'\n",
    "output_root = 'texture_cvl'\n",
    "\n",
    "for writer_id in tqdm(sorted(os.listdir(input_root))):\n",
    "    writer_path = os.path.join(input_root, writer_id)\n",
    "    if not os.path.isdir(writer_path):\n",
    "        continue\n",
    "\n",
    "    for filename in sorted(os.listdir(writer_path)):\n",
    "        if not filename.endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(writer_path, filename)\n",
    "\n",
    "        try:\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            cleaned_lines, _ = segment_lines(image)\n",
    "\n",
    "            cropped_words = segment_words(cleaned_lines)\n",
    "\n",
    "            texture = generate_texture(cropped_words,file_name = image_path)\n",
    "\n",
    "            patches = split_texture(texture)\n",
    "\n",
    "            parts = filename.split(\".\")\n",
    "            base_id = parts[0]\n",
    "            writer_id = parts[0].split(\"_\")[0]\n",
    "            # sample_id = parts[1]\n",
    "            # speed = parts[2].split(\".\")[0]\n",
    "\n",
    "            save_dir = os.path.join(output_root,writer_id,base_id)\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            for i, patch in enumerate(patches):\n",
    "                patch_filename = f\"{base_id}_T{i+1}.png\"\n",
    "                patch_path = os.path.join(save_dir, patch_filename)\n",
    "                cv2.imwrite(patch_path, patch)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed processing: {image_path}\")\n",
    "            print(f\"        {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnEYxsxeSu8T"
   },
   "source": [
    "## Upload Textures to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqN5voHlSzB2"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"texture_cvl\", 'zip', \"texture_cvl\")\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"texture_cvl.zip\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "target_directory = \"/content/drive/MyDrive/Research Level 4/Implementations/Writer Verification Rashmi/data\"\n",
    "!cp texture_cvl.zip \"{target_directory}/\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TdPEccosdlhF",
    "EHBPi56-lEB-",
    "_liSm1k9bxOV",
    "wCjbJ1CqPmwS",
    "Mlern8QZPz6o",
    "RfsVP8oVQY0R",
    "9jiSvzbAQxd7",
    "UnEYxsxeSu8T"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
